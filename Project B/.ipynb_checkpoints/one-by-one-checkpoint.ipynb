{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL.ImageOps import mirror\n",
    "import shutil\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = models.resnet50(pretrained=False).to(device)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)).to(device)\n",
    "model.load_state_dict(torch.load('weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open('Przechwytywanie.PNG').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1=img.size\n",
    "print(x1,y1)\n",
    "M=np.empty((y1,x1,2),dtype=float)\n",
    "C=np.empty((y1,x1),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1\n",
    "for vertical_shift in range(0, x1, step_size):\n",
    "    for horizontal_shift in range(0, y1, step_size):\n",
    "        top=horizontal_shift\n",
    "        bottom=224+horizontal_shift\n",
    "        left=vertical_shift\n",
    "        right=224+vertical_shift\n",
    "        current_crop = img.crop((left, top, right, bottom))\n",
    "        current_tensor = torchvision.transforms.ToTensor()(current_crop).unsqueeze(0).to(device)\n",
    "        output = model(current_tensor)\n",
    "        P = F.softmax(output, dim=1).cpu().data.numpy()\n",
    "        print(P)\n",
    "        y = horizontal_shift\n",
    "        x = vertical_shift\n",
    "        M[y:y+224, x:x+224] = (M[y:y+224, x:x+224] * C[y:y+224, x:x+224, None] + P) / (C[y:y+224, x:x+224, None] + 1)\n",
    "        C[y:y+224, x:x+224, None] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros( (int(y1),int(x1),3), dtype=np.uint8 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=np.argmax(M, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,x1,1):\n",
    "    for j in range (0,y1,1):\n",
    "        if M[j,i]==1:\n",
    "            color_to_paint=[4,86,22]\n",
    "        else:\n",
    "            color_to_paint=[4,50,14]\n",
    "        matrix[j,i]=color_to_paint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgr = Image.fromarray( matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mirror(imgr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
