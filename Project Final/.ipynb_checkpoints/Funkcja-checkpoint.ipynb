{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(dirPhoto,dirModel):\n",
    "    img =imgp= Image.open(dirPhoto).convert(\"RGB\")\n",
    "    x,y=img.size\n",
    "    pix = img.load()\n",
    "    clf = joblib.load(dirModel) #load model with pretrained weights\n",
    "    list_of_colors = [[4,86,22], [4,50,14], [128,128,128],[255,255,153]] #set colors for final representation\n",
    "    pixel=[]\n",
    "    template=np.zeros( (x,y), dtype=np.uint8 ) #model before single pixels deletion\n",
    "    template_final=np.zeros( (x,y), dtype=np.uint8 ) #model after single pixels deletion\n",
    "    for i in range (0,x,1):\n",
    "        for j in range (0,y,1): \n",
    "            pixel.append(pix[i,j])\n",
    "    output=clf.predict(pixel) #fiting list to the model\n",
    "    iterator=0\n",
    "    for i in range (0,x,1):\n",
    "        for j in range (0,y,1):              #converting list to array of x rows and y columns (picture width and height)\n",
    "            template[ i, j]=output[iterator]\n",
    "            iterator+=1\n",
    "    step=3 #radius of neighbours taken\n",
    "    temp=np.zeros(5)\n",
    "    for i in range (0,x,1):\n",
    "        for j in range (0,y,1):\n",
    "            for i2 in range (max(i-step,0),min(i+step,x),1):\n",
    "                for j2 in range (max(j-step,0),min(j+step,y),1):\n",
    "                    temp[template[i2,j2]]=temp[template[i2,j2]]+1 \n",
    "            result=temp.argmax()                                        #removing single pixels\n",
    "            template_final[i,j]=result\n",
    "            temp=np.zeros(5)\n",
    "    matrix = np.zeros( (x,y,3), dtype=np.uint8 ) #matrix after sigle pictures deletion\n",
    "    matrix_test = np.ones( (x,y,3), dtype=np.uint8 ) #matrix before sigle pixels deletion\n",
    "    for i in range (0,x,1):\n",
    "        for j in range (0,y,1):\n",
    "            matrix[i,j]=list_of_colors[template_final[i,j]]    \n",
    "            matrix_test[i,j]=list_of_colors[template[i,j]]\n",
    "    img = Image.fromarray(matrix)\n",
    "    img=img.rotate(-90, Image.NEAREST, expand = 1)\n",
    "    img= img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "    print(imgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app('Przechwytywanie.PNG','model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
